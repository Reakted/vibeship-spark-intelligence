# CLAUDE

## Spark Learnings

*Auto-promoted insights from Spark*

- Large edit on system_tracker.py (901→1143 chars). Consider smaller incremental changes for safer refactoring. *When: micro:large_edit:Edit* (100% reliable, 10 validations)
- Large edit on pipeline.py (652→1036 chars). Consider smaller incremental changes for safer refactoring. *When: micro:large_edit:Edit* (100% reliable, 28 validations)
- Principle: give the sound in these and then after confirmation we can do the hedra *When: Detected from correction pattern (importance: crit* (100% reliable, 11 validations)
- **Protocol 1: Claim Budgeting.** You get a fixed claim budget. Three strong claims without a citation is a fail. Ten vague claims without mechanisms is a fail. Highlight strong claims, add a source or narrow scope for each, and re-run until it passes. This protocol is for any team that produces public-facing assertions. *Quick run: take your last published document. Highlight every sentence that asserts a fact or a should. Count the ones without a source, a scope bound, or an explicit uncertaint *When: signals: ['medium:conditional', 'decision', 'corre* (100% reliable, 6 validations)
- Large edit on advisory_memory_fusion.py (683→1390 chars). Consider smaller incremental changes for safer refactoring. *When: micro:large_edit:Edit* (100% reliable, 5 validations)
- now can we create memories in real time that can be useful, and see how they go through, to the advisory path, on a thing that can be useful, and how the retrieval happens, end to end, and see where the gaps and blockages are *When: signals: ['correction'], session: f919714e-2f2e-42* (98% reliable, 48 validations)